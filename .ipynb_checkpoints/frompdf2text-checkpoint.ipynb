{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "#to match substring in string\n",
    "import fuzzysearch\n",
    "from fuzzysearch import find_near_matches\n",
    "\n",
    "#access structured data from pdf\n",
    "import PyPDF2\n",
    "from docx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "path_data = os.path.join(ROOT_DIR,'datasets/synonyms/synonym_book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camille/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/camille/anaconda3/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../../..'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "\n",
    "from UTILS.utils import from_string_without_whitespace_to_string_withwithespace, extract_bold_text, from_chapter_to_structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using quick pdf converter (free trial) to convert from pdf to doxc. But only until page 90+28 car si non must \n",
    "#buy..... TODO convert all\n",
    "#this notebook is meant to be used on a file that is in doxc and in pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy:\n",
    "#PyPDF2 is reading the text in the proper order, while python-doxc not. Hence we will use the first one to read text,\n",
    "#and the second to help for splitting. Indeed, unfortunately we can not use the result from pyhton-doxc \n",
    "#(text_no_whitespace_bold) to build a skeleton and then complet, as the order is wrong.\n",
    "\n",
    "#main steps:\n",
    "#1. extract needed data: extract bold-text using python-doxc. create a list of titles and subtitles (bold-data)\n",
    "#2. Using PyPDF2, extract all the text (text-data)\n",
    "#3. take each title and look for closest match in the text, creating  anew list of matched titles (Levinshtein dist.)\n",
    "#4. split the text-data using the list of matched title (dataframe: title, info columns)\n",
    "#5. split the info using subtitles as properties, synonyms etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note:\n",
    "#1.for each book such a notebook is necessary. (what makes it hard to automate without mistake: \n",
    "#mistake in the books cf bold, different pattern in each book and eventually chapter,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some issues explaining why we need 3.:\n",
    "#when downloaded from PyPDF2 there is '&' while downloading from python-doxc their is no '&' at least in some e.g. :\n",
    "#from text: 1838Œ1849 (Atractaspididae)    from bold: 1838–1849(Atractaspididae)\n",
    "#from text: Wüster & Broadley              from bold: WüsterBroadley\n",
    "#from text: pl. 2, fig. a                  from bold: pl.fig.a\n",
    "#--> we need to use rules as maximum number of caractere that need to be changed to say their ias a match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypothesis:\n",
    "#bold text is not split within two pages. (otherwise will be problematique)\n",
    "#no two consecutive title or subtitle (always synonyms, or types etc in between)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_title = '2014 Snakes of the world-A catalogue of living and extinct species.pdf'\n",
    "file_path = os.path.join(path_data,book_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract bold text using python-doxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#document = Document('/home/camille/vm_exchange/Lab/snakes/datasets/synonyms/synonym_book/2014 Snakes of the world-A catalogue of living and extinct species - Copie - Copie.docx')\n",
    "document = Document('/home/camille/vm_exchange/Lab/snakes/datasets/synonyms/synonym_book/2014 Snakes of the world-A catalogue of living and extinct species - chapterA.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract bold text\n",
    "r = extract_bold_text(document)\n",
    "text_no_whitespace_bold = r.split('Valid Genera and Species')[-1].strip()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract information needed for our specific book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type locality:|Synonym:|Type:|Fossil records:|Synonyms:|Sources:|Remarks:|Type species:|Types:|Distribution:|Source:|Comment:|Comments:'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find properties \n",
    "pattern = re.compile(r'(Type species:|Distribution:|Sources:|Remarks:|Type locality:|Type:|Types:|Sources:|Source:|Synonym:|Synonyms:)')\n",
    "li_text_no_whitespace_bold = pattern.split(text_no_whitespace_bold)\n",
    "li_properties = list(set([i.strip() for i in li_text_no_whitespace_bold if (i.strip().endswith(':')) & (len(i)<25)]))\n",
    "#in the book they forgot to put in bold after the properties: comment. hence we need to add it manually\n",
    "li_properties = li_properties+['Comment:','Comments:']\n",
    "# create pattern for properties\n",
    "li_properties\n",
    "pattern_properties = ''\n",
    "for p in li_properties:\n",
    "    pattern_properties = pattern_properties+'|'+p\n",
    "pattern_properties = pattern_properties.strip('|')\n",
    "pattern_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of titles and list of subtitles\n",
    "li = list(set([i.strip() for i in li_text_no_whitespace_bold if i not in li_properties]))\n",
    "#python-doxc reading sometimes the index in middle of title\n",
    "pattern = re.compile(r'[A-Z]{1}  ')\n",
    "li = [j.strip() for i in li for j in pattern.split(i)]\n",
    "#due to comment mistake:\n",
    "pattern = re.compile(r'Comment  |Comments  ')\n",
    "li = [j.strip() for i in li for j in pattern.split(i)]\n",
    "li = [i for i in li if len(i)>2]\n",
    "li_st = [i.strip() for i in li if i[0].isdigit()]\n",
    "li_t = [i.strip() for i in li if (i[0].isupper()) & (i[1].isupper()) & (i[1].isupper())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    }
   ],
   "source": [
    "print(len(li_st+li_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract all text using PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1257 page in this pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_file = open(os.path.join(path_data,book_title),'rb')\n",
    "read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "number_of_pages = read_pdf.getNumPages()\n",
    "print('There is %d page in this pdf'%number_of_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page = read_pdf.getPage(491+28)   #(159)#(3+28)\n",
    "page_content = page.extractText()\n",
    "page_content.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put info into structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------paragraph: A\n",
      "ANOMOCHILUS Berg, 1901  (nomen substitutum) (Anomochilidae)\n",
      "ARCHELAPHE Schulz, Böhme &amp; Tillack, 2011 (Colubridae)\n",
      "APLOPELTUR A A.-M.-C. Duméril, 1853 (nomen protectum) (Pareatidae)\n",
      "AUSTRELAPS Worre ll, 196 3a (Elapidae)\n",
      "ARIZONA Kennicott in Baird, 1859a (Colubridae)\n",
      "ATRACTASPIS A. Smith, 1849 in 1838–1849 (Atractaspididae)\n",
      "AGKISTRODON Palisot de Beauvois, 1799\n",
      "ASTROTIA J.G. Fischer, 1855 (Elapidae)\n",
      "APARALLACTUS A. Smith, 1849 in 1838–1849 (Atractaspididae)\n",
      "ANTAIOSERPENS Wells &amp; Wellington, 1985 (Elapidae)\n",
      "ASPIDITES W.C.H. Peters, 1877a (nomen substitutum) (Pythonidae)\n",
      "ADELOPHIS Dugès in Cope, 1879 (Natricidae)\n",
      "ASPIDOMORPHUS Fitzinger, 1843 (Elapidae)\n",
      "ACRANTOPHIS Jan, 1860 in JanSordelli, 1860–1866 (Boidae)\n",
      "AMPLORHINUS A. Smith, 1847 in 1838–1849      42. Amphiesma viperinum (Schenkel, 1901). Verh. Naturf. Ges. Basel (1901–1902) 13(1): 155–156. (Xenochrophis viperinus)\n",
      "ANTARESIA Wells &amp; Wellington, 1984 (Pythonidae)\n",
      "ATRETIUM Cope, 1861e (nomen substitutum) (Natricidae)\n",
      "ANOMALEPIS Jan, 1860 in JanSordelli, 1860–1866 (Anomalepididae)\n",
      "9. Alsophis sibonius Cope, 1879. Proc. Amer. Philos. Soc. 18: 275–278.\n",
      "5. Aspidura drummondhayi Boulenger, 1904d. Spolia Zeylan. 2(7): 95–96, pl.,figs.\n",
      "5. Aipysurus fuscus (Tschudi, 1837). Arch. Naturg. 3(1): 335, pl. 8, figs. 1–7. (Stephanohydra fusca)\n",
      "92. Atractus pantostictus R. FernandesPuorto, 1994. Mem. Inst. Butantan 55(Suppl. 1): 8–12, figs. 1–3, 5.\n",
      "12. Atheris matildae Menegon, DavenportHowell, 2011. Zootaxa (3120): 44–50, fig.(left).\n",
      "19. Amphiesma leucomystax David, Bain, Truong,       Orlov, Vogel, ThanhZiegler, 2007. Zootaxa (1462): 43–46, figs. 1–7.\n",
      "2. Apostolepis ambinigra (W.C.H. Peters, 1869). Mber. Königl. Akad. Wiss. Berlin 1869(5): 438–439, pl., fig. 2–2c. (Rhynchonyx ambiniger)\n",
      "64. Atractus major Boulenger, 1894a. Cat. Snakes\n",
      "30. Amphiesma platyceps (Blyth, 1854a). J. Proc. Asiatic Soc. Bengal 23(3): 297–298. (Tropidonotus platyceps)\n",
      "6. Atheris chlorechis (Pel, 1851). Ned.Tijdschr. Jagtkunde 1: 172–173. (Vipera chlorechis)\n",
      "41. Atractus francicopaivai Silva-Haad, 2004. Rev. Acad. Colomb. Cienc. 28(108): 426–428, figs. 24–25.\n",
      "67. Atractus matthewi MarkezichBarrio-Amorgós, 2004. Bull. Maryland Herp. Soc. 40(3): 112–117, figs. 1a, 2.\n",
      "4. Anilios australis Gray, 1845. Cat. Lizards Brit. Mus.: 135.\n",
      "31. Amphiesma popei (K.P. Schmidt, 1925a). Amer. Mus. Novit. (157): 3. (Natrix popei)\n"
     ]
    }
   ],
   "source": [
    "#for this specific book: add all page text info of a chapter, then create strucutred data for this chapter and\n",
    "#continue with the next one\n",
    "chapter_content = ''\n",
    "for i in range(3+28,811+28):\n",
    "    \n",
    "    #print(i)\n",
    "    page = read_pdf.getPage(i)\n",
    "    page_content = page.extractText()\n",
    "    li_page = page_content.split('\\n')\n",
    "    li_page_clean = li_page.copy()\n",
    "    \n",
    "    ### if empty page pass it ###\n",
    "    if len(li_page)<2:\n",
    "        pass \n",
    "    \n",
    "    ### if in middle of chapter ###\n",
    "    elif 'Snakes of the World' in li_page[0]:\n",
    "        page_nbr = li_page[0].split('Snakes of the World')[0]\n",
    "        \n",
    "        #remove the page if it starts with the number, otherwise it means that its a new paragraph (i.e. not having \n",
    "        #the page written on the top...but then it should not have snakes of the world written)\n",
    "        if li_page[1].startswith(page_nbr):\n",
    "            first_element = li_page[1].split(page_nbr)[-1]\n",
    "            li_page_clean = [first_element] + li_page[2:]\n",
    "        else:\n",
    "            print('snakes of the world but no new paragraph weird! check on book page %s'%(i-28))\n",
    "        #add info of this page to the chapter\n",
    "        chapter_content = chapter_content + ' ' + ' '.join(li_page_clean)\n",
    "    elif 'Snakes of the World' in li_page[1]:    \n",
    "        page_nbr = li_page[0]\n",
    "        if li_page[0]!=li_page[2]:\n",
    "            print('weird! show page %d'%i)\n",
    "        li_page_clean = li_page[3:]\n",
    "        \n",
    "    ### if new paragraph, remove page and keep rest as title ### \n",
    "    else:\n",
    "        #if not first paragraph, register all info you have of the paragraph from before\n",
    "        if chapter_content!='':\n",
    "            start_time = time.time()\n",
    "            R, title_not_matched, li_matched_title, li_distance = from_chapter_to_structured_data(text=chapter_content, \n",
    "                                                                                                  li_title=li_t+li_st)\n",
    "            print(\"--- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "            li_title = [R[i] for i in range(len(R)) if i%2==0]\n",
    "            li_info = [R[i] for i in range(len(R)) if i%2!=0]\n",
    "            print(len(li_title[0:-1]), len(li_info))\n",
    "            l = max(len(li_title), len(li_info))\n",
    "            df = pd.DataFrame.from_dict({'title':li_title[0:l], 'info':li_info[0:l]})\n",
    "            df.to_csv(os.path.join(path_data,'df_info_chapter_'+title+'.csv'), index=False, sep=';')\n",
    "            pickle.dump(title_not_matched, open(os.path.join(path_data,'li_title_notmatched_'+title+'.pkl'), 'wb'))\n",
    "            pickle.dump(li_matched_title, open(os.path.join(path_data,'li_matched_title_'+title+'.pkl'), 'wb'))\n",
    "            pickle.dump(li_distance, open(os.path.join(path_data,'li_distance_'+title+'.pkl'), 'wb'))\n",
    "\n",
    "        #otherwise, pass to the next one\n",
    "        #remove any digits from the first element of the page\n",
    "        first_element = (' '.join(li_page[0:2]).lstrip('0123456789')).strip().strip('ƒ')\n",
    "        #print(first_element, li_page[0], li_page[0].split(first_element))\n",
    "        page_nbr = li_page[0].split(first_element)[0]\n",
    "        title = first_element[0]\n",
    "        print('-------------------paragraph: %s'%title)\n",
    "        first_element = first_element[1:]\n",
    "        li_page_clean = [first_element] + li_page[2:]\n",
    "        #add info of this page to the chapter\n",
    "        chapter_content = ' '.join(li_page_clean)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "start_time = time.time()\n",
    "R = from_chapter_to_structured_data(text=chapter_content, li_title=li_t+li_st)\n",
    "print(\"--- %s seconds ---\" % round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#examples for find near match\n",
    "title = 'AFROTYPHLOPSBroadleyWallach,2009(Typhlopidae)'\n",
    "text = ''.join(chapter_content.split(' '))\n",
    "r = find_near_matches(title, text, max_l_dist=2, max_deletions=max(int(0.05*len(title)),1), \n",
    "                      max_insertions=1, max_substitutions=0)\n",
    "print(r)\n",
    "new_title = text[r[0][0]:r[0][1]]\n",
    "new_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
