{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import numpy\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "#to set connection with Flickr API\n",
    "from flickrapi import FlickrAPI\n",
    "\n",
    "#image\n",
    "from PIL import Image\n",
    "\n",
    "#url open to get image\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#date\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "#plot\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camille/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../../..'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "\n",
    "from UTILS.utils import get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "path_data = os.path.join(ROOT_DIR,'datasets/flickr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#license info: https://www.flickr.com/services/api/flickr.photos.licenses.getInfo.html\n",
    "#license:0 = 'All rights reserved'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get these data follow the direction of: http://joequery.me/code/flickr-api-image-search-python/\n",
    "FLICKR_PUBLIC = 'dd0cb0ced4e83452f8d49cb3d534707d'\n",
    "FLICKR_SECRET = '4c568d2002b5506e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr = FlickrAPI(FLICKR_PUBLIC, FLICKR_SECRET, format='parsed-json')\n",
    "extras = 'description,geo,tags,url_c,owner_name,date_taken,license'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create appropriate folder if not existing\n",
    "if not os.path.exists(path_data):\n",
    "    os.makedirs(path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download species and their synonymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dowload dictionary owith keys=species, value=list of its synonyms\n",
    "dico_syn = pickle.load(open(os.path.join(ROOT_DIR,'datasets','synonyms','dico_species_lisyn.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case to erase all\n",
    "#shutil.rmtree(os.path.join(path_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFO:\n",
    "#for more parameter options: https://www.flickr.com/services/api/flickr.photos.search.html\n",
    "#tags (Optional): A comma-delimited list of tags. Photos with one or more (or all tags by changing tags_mode)of the \n",
    "#tags listed will be returned. You can exclude results that match a term by prepending it with a - character.\n",
    "#http://joequery.me/code/flickr-api-image-search-python/\n",
    "#lisence info: https://www.flickr.com/services/api/flickr.photos.licenses.getInfo.html\n",
    "#geolocalisation should not be used, as for example picture might be taken from a museum. we should add geolocalisation \n",
    "#based on 'biology' knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 3730 species\n"
     ]
    }
   ],
   "source": [
    "#create a list of species\n",
    "li_species = list(dico_syn.keys())\n",
    "if len(li_species)!=len(set(li_species)):\n",
    "    print('EREUR non unique species name')\n",
    "    sys.exit()\n",
    "print('There is %d species'%len(li_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create appropriate folder if needed\n",
    "for species in li_species:\n",
    "    folder_path_s = os.path.join(path_data,species)\n",
    "    if not os.path.exists(folder_path_s):\n",
    "        os.makedirs(folder_path_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download image from flickr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea: collect all the image from the begining date, and until no more new image are outcome. In this way one can \n",
    "#rerun at anytime to grab only the new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.65 percent of the species were already requested until date 01_12_2018\n",
      "Hence, we have 730 species left to query for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [38:20<00:00,  3.15s/it] \n"
     ]
    }
   ],
   "source": [
    "#choose starting date and we will take species that was not taken at this starting date\n",
    "date = '01_12_2018' #in string otherwise might change if we run over two days\n",
    "f = os.path.join(path_data,'li_species_done_'+date+'.pkl')\n",
    "if len(glob.glob(f))>0:\n",
    "    li_species_done = pickle.load(open(f, 'rb'))\n",
    "else:\n",
    "    li_species_done = []\n",
    "print('%.2f percent of the species were already requested until date %s'%(len(li_species_done)/len(li_species)*100,\n",
    "                                                                        date))\n",
    "\n",
    "#download images from flickr\n",
    "#Go in each species folder, and downlaod all the photos with a taken date greater than or equal to the maximum one \n",
    "#recorded in the species-metadata file if it exist, otherwise download it from the begining (\"0000-00-00 00:00:00\")\n",
    "#While downloading an image, if there is an error from flickr stop the code (might be connection error). Then you \n",
    "#simply need to rerun it perhaps few minutes later\n",
    "li_species_to_do = [x for x in li_species if x not in li_species_done[0:-1]]\n",
    "print('Hence, we have %d species left to query for'%len(li_species_to_do))\n",
    "\n",
    "for species in tqdm.tqdm(li_species_to_do):\n",
    "    \n",
    "    #save all previous species as done until that specific date\n",
    "    li_species_done.append(species)\n",
    "    pickle.dump(li_species_done, open(os.path.join(path_data,'li_species_done_'+date+'.pkl'), 'wb'))\n",
    "    \n",
    "    #list of synonyms for the species\n",
    "    #li_syn = eval(df_species_syn[df_species_syn['binomial']==species]['li_synonyms_final'].values[0]) + [species]\n",
    "    li_syn = dico_syn[species] + [species]\n",
    "    \n",
    "    #initialize folder path for this species\n",
    "    folder_path_s = os.path.join(path_data, species)\n",
    "    \n",
    "    #iterate through each species synonyms\n",
    "    for species_word in li_syn:\n",
    "        \n",
    "        #make sur li_syn is a list\n",
    "        if len(species_word)==1:\n",
    "            print('ERROR:',species_word, species)\n",
    "            sys.exit()\n",
    "            \n",
    "        #initialization\n",
    "        t = \"0000-00-00 00:00:00\"\n",
    "        df_old = pd.DataFrame()\n",
    "    \n",
    "        #if the new collection of images is empty, then stop it, otherwise continue with the last taken date\n",
    "        while True:\n",
    "\n",
    "            #open the existing metadata file if any, and use the max taken date to grab data from that point instead\n",
    "            old_meta_data_file = os.path.join(folder_path_s,'flickr_df_'+species+'.csv')\n",
    "            if len(glob.glob(old_meta_data_file))>0:\n",
    "                #date will be: Timestamp('2017-04-30 17:12:52')\n",
    "                df_old = pd.read_csv(old_meta_data_file, parse_dates=['datetaken'], index_col=False, sep=';')\n",
    "                \n",
    "                #we need to take minus one day as min_taken_date is apparently working at day level, and before saving\n",
    "                #we'll need to remove possibly duplicates (might happen if several picture taken the same day but we stop\n",
    "                #at a \"middle picture of the day\"). Also we convert to good format for flickr query\n",
    "                df_ = df_old[df_old['species_word']==species_word].copy()\n",
    "                if df_.shape[0]>0:\n",
    "                    t = (max(df_['datetaken'].tolist()) - dt.timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    #print('we will use as starting date %s'%str(t))\n",
    "            \n",
    "            #take at most 5 times if their is a connection error connection error )\n",
    "            k = 0\n",
    "            while k<5:\n",
    "                try:\n",
    "                    image_data = flickr.photos.search(text='\\\"'+species_word+'\\\"', content_type=1, media=\"photos\", \n",
    "                                                      per_page=500, extras=extras, min_taken_date=t)\n",
    "                    k = 5\n",
    "                except KeyboardInterrupt:\n",
    "                    raise\n",
    "                except Exception as e:\n",
    "                    k = k+1\n",
    "                    print('Not able to DOWNLOAD flickr img for species %s, due to error: %s, lets SLEEP'%(species,e))\n",
    "                    # sleep for 5 seconds\n",
    "                    if k==4:\n",
    "                        sys.exit()\n",
    "                    image_data=None\n",
    "                    time.sleep(5)\n",
    "                    \n",
    "            if image_data==None:\n",
    "                #print('image is none get out of loop')\n",
    "                break\n",
    "                \n",
    "            #download image if its a new one\n",
    "            for i, photo in enumerate(image_data['photos']['photo']): #besides photos there is only a 'stat' key\n",
    "                if 'url_c' in photo:\n",
    "                    url = photo['url_c']\n",
    "                    f = os.path.join(folder_path_s,'flickr_'+species+'_'+photo['id']+\".png\")\n",
    "                    get_image(url=url, path=f, name=species)\n",
    "\n",
    "            #create new metadata file with all the images (old and new)\n",
    "            df_new = pd.DataFrame(image_data['photos']['photo'])\n",
    "            df_new['species_word'] = species_word\n",
    "            df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "\n",
    "            #save and remove duplicates (before: uniform the id type(as when we save and open the str get converted \n",
    "            #to int))\n",
    "            if df.shape[0]>0:\n",
    "                df['id'] = df['id'].astype(int) \n",
    "                #drop duplicates due to dates that must overlap when re-query data for the second time\n",
    "                #we keep trace of each image evn if its already find for another syn, in this way we would directly know\n",
    "                #which image respond ti which species-word, and also which last-taken date correspond to which species\n",
    "                df = df.drop_duplicates(subset=['id', 'species_word'], keep='first', inplace=False)\n",
    "                #save metadata for each images of this species (note: might be empty if no images was collected)\n",
    "                df.to_csv(os.path.join(folder_path_s,'flickr_df_'+species+'.csv'), index=False, sep=';')\n",
    "\n",
    "            #print(df_old.shape,df_new.shape,df.shape) #to debug\n",
    "            #if there was already data collected and the new one brought some more data (not tru now that we have several\n",
    "            #names per species)\n",
    "            #if (df_old.shape[0]>0) and (df.shape[0]>df_old.shape[0]):\n",
    "            #    print('species %s needed two collected data'%species)\n",
    "            #if no more data was bring last time\n",
    "            if df.shape[0]==df_old.shape[0]: #wrong: df_new.shape[0]==0: indeed we can gather images that are already (-1d)\n",
    "                del image_data\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check amount of flickr images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 57828 images collected from Flickr\n"
     ]
    }
   ],
   "source": [
    "#keeping meta data of only the images we truely have \n",
    "#look at the actual image we really have\n",
    "li_flickr_images = []\n",
    "for species in glob.glob(os.path.join(path_data,'*')):\n",
    "    li_flickr_images.extend([x for x in glob.glob(os.path.join(species,'*')) if x.endswith('.png')])\n",
    "len(li_flickr_images)\n",
    "print('We have %d images collected from Flickr'%len(li_flickr_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create one csv file with all metadata info from each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove images in several species (can happen if an image has two species-word in different species)\n",
    "li_test = []\n",
    "for i in li_flickr_images:\n",
    "    li_test.append(i.split('/')[-1].split('_')[-1].split('.')[0])\n",
    "c = Counter(li_test)\n",
    "c = {k:v for k,v in c.items() if v>1}\n",
    "id_to_be_removed = list(set(c.keys()))\n",
    "if len(id_to_be_removed)>0:\n",
    "    print('%d images appears in different species, we will remove them'%len(id_to_be_removed))\n",
    "\n",
    "li_flickr_images_= li_flickr_images.copy()\n",
    "for i in li_flickr_images:\n",
    "    if i.split('/')[-1].split('_')[-1].split('.')[0] in id_to_be_removed:\n",
    "        #delete file\n",
    "        os.remove(i)\n",
    "        #removing also from the list\n",
    "        li_flickr_images_.remove(i)\n",
    "li_flickr_images = li_flickr_images_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3736/3736 [02:01<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885146, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>context</th>\n",
       "      <th>datetaken</th>\n",
       "      <th>datetakengranularity</th>\n",
       "      <th>datetakenunknown</th>\n",
       "      <th>description</th>\n",
       "      <th>farm</th>\n",
       "      <th>geo_is_contact</th>\n",
       "      <th>geo_is_family</th>\n",
       "      <th>geo_is_friend</th>\n",
       "      <th>...</th>\n",
       "      <th>place_id</th>\n",
       "      <th>secret</th>\n",
       "      <th>server</th>\n",
       "      <th>species</th>\n",
       "      <th>species_word</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url_c</th>\n",
       "      <th>width_c</th>\n",
       "      <th>woeid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-16 09:48:21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Russia: Rostov Oblast, 11.5 km W...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6x9R3.VYUrzZVccn_Q</td>\n",
       "      <td>1fcbb40f2d</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>Vipera renardi</td>\n",
       "      <td>Vipera [renardi]</td>\n",
       "      <td>viperidae vipera ursinii renardi steppeviper r...</td>\n",
       "      <td>Viperidae: Vipera renardi renardi (Steppe Vipe...</td>\n",
       "      <td>https://farm2.staticflickr.com/1743/2761364125...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>90612105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-16 18:24:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Russia: Rostov Oblast, 6 km NW o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6x9R3.VYUrzZVccn_Q</td>\n",
       "      <td>6354620178</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Vipera renardi</td>\n",
       "      <td>Vipera [renardi]</td>\n",
       "      <td>viperidae vipera ursinii renardi steppeviper r...</td>\n",
       "      <td>Viperidae: Vipera renardi renardi (Steppe Vipe...</td>\n",
       "      <td>https://farm1.staticflickr.com/886/27613634797...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>90612105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-16 18:27:31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Russia: Rostov Oblast, 6 km NW o...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6x9R3.VYUrzZVccn_Q</td>\n",
       "      <td>7c9a11b846</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>Vipera renardi</td>\n",
       "      <td>Vipera [renardi]</td>\n",
       "      <td>viperidae vipera ursinii renardi steppeviper r...</td>\n",
       "      <td>Viperidae: Vipera renardi renardi (Steppe Vipe...</td>\n",
       "      <td>https://farm2.staticflickr.com/1725/4248392897...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>90612105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  context            datetaken  datetakengranularity  \\\n",
       "0      16.0      0.0  2018-05-16 09:48:21                   0.0   \n",
       "1      16.0      0.0  2018-05-16 18:24:55                   0.0   \n",
       "2      16.0      0.0  2018-05-16 18:27:31                   0.0   \n",
       "\n",
       "   datetakenunknown                                        description  farm  \\\n",
       "0               0.0  {'_content': 'Russia: Rostov Oblast, 11.5 km W...   2.0   \n",
       "1               0.0  {'_content': 'Russia: Rostov Oblast, 6 km NW o...   1.0   \n",
       "2               0.0  {'_content': 'Russia: Rostov Oblast, 6 km NW o...   2.0   \n",
       "\n",
       "   geo_is_contact  geo_is_family  geo_is_friend     ...      \\\n",
       "0             0.0            0.0            0.0     ...       \n",
       "1             0.0            0.0            0.0     ...       \n",
       "2             0.0            0.0            0.0     ...       \n",
       "\n",
       "             place_id      secret  server         species      species_word  \\\n",
       "0  6x9R3.VYUrzZVccn_Q  1fcbb40f2d  1743.0  Vipera renardi  Vipera [renardi]   \n",
       "1  6x9R3.VYUrzZVccn_Q  6354620178   886.0  Vipera renardi  Vipera [renardi]   \n",
       "2  6x9R3.VYUrzZVccn_Q  7c9a11b846  1725.0  Vipera renardi  Vipera [renardi]   \n",
       "\n",
       "                                                tags  \\\n",
       "0  viperidae vipera ursinii renardi steppeviper r...   \n",
       "1  viperidae vipera ursinii renardi steppeviper r...   \n",
       "2  viperidae vipera ursinii renardi steppeviper r...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Viperidae: Vipera renardi renardi (Steppe Vipe...   \n",
       "1  Viperidae: Vipera renardi renardi (Steppe Vipe...   \n",
       "2  Viperidae: Vipera renardi renardi (Steppe Vipe...   \n",
       "\n",
       "                                               url_c  width_c       woeid  \n",
       "0  https://farm2.staticflickr.com/1743/2761364125...    800.0  90612105.0  \n",
       "1  https://farm1.staticflickr.com/886/27613634797...    800.0  90612105.0  \n",
       "2  https://farm2.staticflickr.com/1725/4248392897...    800.0  90612105.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "li_df = []\n",
    "for species in tqdm.tqdm(glob.glob(os.path.join(path_data,'*'))):\n",
    "    csv_f = glob.glob(os.path.join(species,'*.csv'))\n",
    "    if len(csv_f)==1:\n",
    "        df = pd.read_csv(csv_f[0], sep=';', index_col=False)\n",
    "        df['species'] = species.split('/')[-1]\n",
    "        li_df.append(df)\n",
    "        del df\n",
    "df_all = pd.concat(li_df, ignore_index=True)\n",
    "print(df_all.shape)\n",
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885146, 33)\n",
      "(1289598, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>context</th>\n",
       "      <th>datetaken</th>\n",
       "      <th>datetakengranularity</th>\n",
       "      <th>datetakenunknown</th>\n",
       "      <th>description</th>\n",
       "      <th>farm</th>\n",
       "      <th>geo_is_contact</th>\n",
       "      <th>geo_is_family</th>\n",
       "      <th>geo_is_friend</th>\n",
       "      <th>...</th>\n",
       "      <th>server</th>\n",
       "      <th>species</th>\n",
       "      <th>species_word</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url_c</th>\n",
       "      <th>width_c</th>\n",
       "      <th>woeid</th>\n",
       "      <th>saved_img_id</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-16 09:48:21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Russia: Rostov Oblast, 11.5 km W...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>Vipera renardi</td>\n",
       "      <td>Vipera [renardi]</td>\n",
       "      <td>viperidae vipera ursinii renardi steppeviper r...</td>\n",
       "      <td>Viperidae: Vipera renardi renardi (Steppe Vipe...</td>\n",
       "      <td>https://farm2.staticflickr.com/1743/2761364125...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>90612105.0</td>\n",
       "      <td>flickr_Vipera renardi_27613641257.png</td>\n",
       "      <td>/home/camille/vm_exchange/Lab/snakes/datasets/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-16 18:24:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Russia: Rostov Oblast, 6 km NW o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Vipera renardi</td>\n",
       "      <td>Vipera [renardi]</td>\n",
       "      <td>viperidae vipera ursinii renardi steppeviper r...</td>\n",
       "      <td>Viperidae: Vipera renardi renardi (Steppe Vipe...</td>\n",
       "      <td>https://farm1.staticflickr.com/886/27613634797...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>90612105.0</td>\n",
       "      <td>flickr_Vipera renardi_27613634797.png</td>\n",
       "      <td>/home/camille/vm_exchange/Lab/snakes/datasets/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-16 18:27:31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Russia: Rostov Oblast, 6 km NW o...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>Vipera renardi</td>\n",
       "      <td>Vipera [renardi]</td>\n",
       "      <td>viperidae vipera ursinii renardi steppeviper r...</td>\n",
       "      <td>Viperidae: Vipera renardi renardi (Steppe Vipe...</td>\n",
       "      <td>https://farm2.staticflickr.com/1725/4248392897...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>90612105.0</td>\n",
       "      <td>flickr_Vipera renardi_42483928971.png</td>\n",
       "      <td>/home/camille/vm_exchange/Lab/snakes/datasets/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  context            datetaken  datetakengranularity  \\\n",
       "0      16.0      0.0  2018-05-16 09:48:21                   0.0   \n",
       "1      16.0      0.0  2018-05-16 18:24:55                   0.0   \n",
       "2      16.0      0.0  2018-05-16 18:27:31                   0.0   \n",
       "\n",
       "   datetakenunknown                                        description  farm  \\\n",
       "0               0.0  {'_content': 'Russia: Rostov Oblast, 11.5 km W...   2.0   \n",
       "1               0.0  {'_content': 'Russia: Rostov Oblast, 6 km NW o...   1.0   \n",
       "2               0.0  {'_content': 'Russia: Rostov Oblast, 6 km NW o...   2.0   \n",
       "\n",
       "   geo_is_contact  geo_is_family  geo_is_friend  \\\n",
       "0             0.0            0.0            0.0   \n",
       "1             0.0            0.0            0.0   \n",
       "2             0.0            0.0            0.0   \n",
       "\n",
       "                         ...                          server         species  \\\n",
       "0                        ...                          1743.0  Vipera renardi   \n",
       "1                        ...                           886.0  Vipera renardi   \n",
       "2                        ...                          1725.0  Vipera renardi   \n",
       "\n",
       "       species_word                                               tags  \\\n",
       "0  Vipera [renardi]  viperidae vipera ursinii renardi steppeviper r...   \n",
       "1  Vipera [renardi]  viperidae vipera ursinii renardi steppeviper r...   \n",
       "2  Vipera [renardi]  viperidae vipera ursinii renardi steppeviper r...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Viperidae: Vipera renardi renardi (Steppe Vipe...   \n",
       "1  Viperidae: Vipera renardi renardi (Steppe Vipe...   \n",
       "2  Viperidae: Vipera renardi renardi (Steppe Vipe...   \n",
       "\n",
       "                                               url_c  width_c       woeid  \\\n",
       "0  https://farm2.staticflickr.com/1743/2761364125...    800.0  90612105.0   \n",
       "1  https://farm1.staticflickr.com/886/27613634797...    800.0  90612105.0   \n",
       "2  https://farm2.staticflickr.com/1725/4248392897...    800.0  90612105.0   \n",
       "\n",
       "                            saved_img_id  \\\n",
       "0  flickr_Vipera renardi_27613641257.png   \n",
       "1  flickr_Vipera renardi_27613634797.png   \n",
       "2  flickr_Vipera renardi_42483928971.png   \n",
       "\n",
       "                                            img_path  \n",
       "0  /home/camille/vm_exchange/Lab/snakes/datasets/...  \n",
       "1  /home/camille/vm_exchange/Lab/snakes/datasets/...  \n",
       "2  /home/camille/vm_exchange/Lab/snakes/datasets/...  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add var\n",
    "df_all['saved_img_id'] = df_all.apply(lambda x: 'flickr_'+x['species']+'_'+str(x['id'])+\".png\",axis=1)\n",
    "df_all['img_path'] = df_all.apply(lambda x: os.path.join(path_data,x['species'], x['saved_img_id']), axis=1)\n",
    "print(df_all.shape)\n",
    "#keeping only the images we truely have \n",
    "df_all = df_all[df_all['img_path'].isin(li_flickr_images)]\n",
    "print(df_all.shape)\n",
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57828, 2)\n",
      "(57828, 32)\n",
      "(57828, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species_word</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>context</th>\n",
       "      <th>datetaken</th>\n",
       "      <th>datetakengranularity</th>\n",
       "      <th>datetakenunknown</th>\n",
       "      <th>description</th>\n",
       "      <th>farm</th>\n",
       "      <th>geo_is_contact</th>\n",
       "      <th>...</th>\n",
       "      <th>secret</th>\n",
       "      <th>server</th>\n",
       "      <th>species</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url_c</th>\n",
       "      <th>width_c</th>\n",
       "      <th>woeid</th>\n",
       "      <th>saved_img_id</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6796830748</td>\n",
       "      <td>[l, Pseudoelaps atropolios, Aspidomorphus squa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-02-29 19:14:05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Lamington National Park, Qld'}</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3b0faf2da2</td>\n",
       "      <td>7204.0</td>\n",
       "      <td>Cacophis squamulosus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cacophis squamulosus (Golden-crowned Snake)</td>\n",
       "      <td>https://farm8.staticflickr.com/7204/6796830748...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flickr_Cacophis squamulosus_6796830748.png</td>\n",
       "      <td>/home/camille/vm_exchange/Lab/snakes/datasets/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6797027978</td>\n",
       "      <td>[California kingsnake]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-04-22 14:11:35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'_content': 'Santa Clara County 4/22/2012'}</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>b5d546df2e</td>\n",
       "      <td>7203.0</td>\n",
       "      <td>Lampropeltis californiae</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California Kingsnake</td>\n",
       "      <td>https://farm8.staticflickr.com/7203/6797027978...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flickr_Lampropeltis californiae_6797027978.png</td>\n",
       "      <td>/home/camille/vm_exchange/Lab/snakes/datasets/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6799008978</td>\n",
       "      <td>[Emerald tree boa]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-03-01 16:24:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'_content': 'emerald tree boa wpz'}</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>c93e0025bd</td>\n",
       "      <td>7181.0</td>\n",
       "      <td>Corallus caninus</td>\n",
       "      <td>park tree woodland zoo snake boa emerald seatl...</td>\n",
       "      <td>emerald tree boa wpz 100_0301R3</td>\n",
       "      <td>https://farm8.staticflickr.com/7181/6799008978...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flickr_Corallus caninus_6799008978.png</td>\n",
       "      <td>/home/camille/vm_exchange/Lab/snakes/datasets/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                       species_word  accuracy  \\\n",
       "0  6796830748  [l, Pseudoelaps atropolios, Aspidomorphus squa...       0.0   \n",
       "1  6797027978                             [California kingsnake]       0.0   \n",
       "2  6799008978                                 [Emerald tree boa]       0.0   \n",
       "\n",
       "   context            datetaken  datetakengranularity  datetakenunknown  \\\n",
       "0      0.0  2012-02-29 19:14:05                   0.0               0.0   \n",
       "1      0.0  2011-04-22 14:11:35                   0.0               0.0   \n",
       "2      0.0  2012-03-01 16:24:59                   0.0               1.0   \n",
       "\n",
       "                                    description  farm  geo_is_contact  \\\n",
       "0  {'_content': 'Lamington National Park, Qld'}   8.0             NaN   \n",
       "1  {'_content': 'Santa Clara County 4/22/2012'}   8.0             NaN   \n",
       "2          {'_content': 'emerald tree boa wpz'}   8.0             NaN   \n",
       "\n",
       "                         ...                              secret  server  \\\n",
       "0                        ...                          3b0faf2da2  7204.0   \n",
       "1                        ...                          b5d546df2e  7203.0   \n",
       "2                        ...                          c93e0025bd  7181.0   \n",
       "\n",
       "                    species  \\\n",
       "0      Cacophis squamulosus   \n",
       "1  Lampropeltis californiae   \n",
       "2          Corallus caninus   \n",
       "\n",
       "                                                tags  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  park tree woodland zoo snake boa emerald seatl...   \n",
       "\n",
       "                                         title  \\\n",
       "0  Cacophis squamulosus (Golden-crowned Snake)   \n",
       "1                         California Kingsnake   \n",
       "2              emerald tree boa wpz 100_0301R3   \n",
       "\n",
       "                                               url_c  width_c  woeid  \\\n",
       "0  https://farm8.staticflickr.com/7204/6796830748...    800.0    NaN   \n",
       "1  https://farm8.staticflickr.com/7203/6797027978...    800.0    NaN   \n",
       "2  https://farm8.staticflickr.com/7181/6799008978...    800.0    NaN   \n",
       "\n",
       "                                     saved_img_id  \\\n",
       "0      flickr_Cacophis squamulosus_6796830748.png   \n",
       "1  flickr_Lampropeltis californiae_6797027978.png   \n",
       "2          flickr_Corallus caninus_6799008978.png   \n",
       "\n",
       "                                            img_path  \n",
       "0  /home/camille/vm_exchange/Lab/snakes/datasets/...  \n",
       "1  /home/camille/vm_exchange/Lab/snakes/datasets/...  \n",
       "2  /home/camille/vm_exchange/Lab/snakes/datasets/...  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one line per id making the species_word columns a list, so that we know which image react to which\n",
    "#species word (from the same species, otherwise will be already removed)\n",
    "df_all1 = df_all.groupby('id')['species_word'].agg(lambda x: list(set(x))).reset_index()\n",
    "df_all1 = df_all1.rename(columns={0:'species_word'})\n",
    "print(df_all1.shape)\n",
    "df_all2 = df_all.drop(['species_word'], inplace=False, axis=1).copy()\n",
    "df_all2 = df_all2.drop_duplicates(subset=['id','species','img_path'], keep='first', inplace=False)\n",
    "print(df_all2.shape)\n",
    "df_all_final = pd.merge(df_all1, df_all2, how='outer', on='id')\n",
    "print(df_all_final.shape)\n",
    "df_all_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: we have 48 images that does not appear in the df\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camille/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#see if for each image we have its info in df\n",
    "d = len(li_flickr_images)-df_all_final.shape[0]\n",
    "if d!=0:\n",
    "    print('ERROR: we have %d images that does not appear in the df, we will remove them'%d)\n",
    "    \n",
    "#lets remove them\n",
    "li_= [i for i in li_flickr_images if i not in df_all['img_path'].tolist()]\n",
    "len(li_)   \n",
    "li_flickr_images_= li_flickr_images.copy()\n",
    "print(len(li_flickr_images))\n",
    "for i in li_:\n",
    "    #delete file\n",
    "    os.remove(i)\n",
    "    #removing also from the list\n",
    "    li_flickr_images_.remove(i)\n",
    "li_flickr_images = li_flickr_images_\n",
    "print(len(li_flickr_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that each image appear only once:\n",
    "if max(list(df_all_final['id'].value_counts().values))!=1:\n",
    "    print('ERROR: we have images that appear twice in teh df'%d)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify if we have the exact same amount of images and info\n",
    "df_all_final.shape[0]!=len(li_flickr_images):\n",
    "    print('ERROR: still not same amount of saved flickr images and info of flickr images')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57828, 33)\n"
     ]
    }
   ],
   "source": [
    "#save metadata info (might not be of same size of number of collected images)\n",
    "print(df_all_final.shape)\n",
    "df_all_final.to_csv(os.path.join(path_data,'flickr_image_info.csv'), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 percent of flickr image were not taken this second time due perhaps to people removing their images\n"
     ]
    }
   ],
   "source": [
    "#Note on old data:\n",
    "#4'637 out of 16'210 were not taken the second time, but can not be added due to missing url, longitude, lat. info\n",
    "x = 4637/16210*100\n",
    "print('%d percent of flickr image were not taken this second time due perhaps to people removing their images'%x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
